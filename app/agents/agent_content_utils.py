import json
import re
import html
import string
import random
from typing import Dict, Any, List
import unicodedata

# LISTA DE PATRONES TEMÃTICOS A EXCLUIR (contextuales, triviales, sin valor investigativo)
EXCLUDED_TOPIC_PATTERNS = {
    # EfemÃ©rides y "noches temÃ¡ticas"
    r'noche de los?\\s+',
    r'dÃ­a de los?\\s+',
    r'semana de los?\\s+',
    r'mes de los?\\s+',
    r'festival de\\s+',
    r'fiesta de\\s+',
    r'celebraciÃ³n de\\s+',
    r'conmemoraciÃ³n de\\s+',
    
    # Paros y conflictos sin anÃ¡lisis profundo
    r'\\bparo de\\s+',
    r'\\bhuelga de\\s+',
    r'\\bparo nacional',
    r'\\bbloqueo de\\s+',
    r'\\bmarcha de\\s+',
    r'\\bprotesta\\b',
    
    # Eventos superficiales
    r'sorteo de\\s+',
    r'concurso de\\s+',
    r'giveaway',
    r'promo\\b',
    r'promociÃ³n\\b',
    
    # Cobertura de noticias puras (sin anÃ¡lisis)
    r'se robaron?\\b',
    r'fue detenido',
    r'muriÃ³|muere',
    r'accidente de\\s+',
    r'choque en\\s+',
}

# Lista de palabras clave que indican contenido de anÃ¡lisis profundo
# Expandida para incluir anÃ¡lisis econÃ³mico, polÃ­tico y de tendencias internacionales
DEEP_ANALYSIS_KEYWORDS = {
    # Palabras de anÃ¡lisis general
    'anÃ¡lisis', 'impacto', 'estrategia', 'estrategias', 'causas', 'consecuencias',
    'investigaciÃ³n', 'investigamos', 'explicamos', 'entendemos', 'cÃ³mo', 'por quÃ©',
    'implicaciones', 'perspectiva', 'tendencias', 'proyecciÃ³n', 'futuro',
    'contexto', 'antecedentes', 'comparaciÃ³n', 'diferencia', 'economÃ­a',
    
    # Palabras de impacto y relevancia
    'impacto econÃ³mico', 'impacto social', 'riesgos', 'oportunidades',
    'desafÃ­os', 'soluciones', 'alternativas', 'enfoque', 'abordaje',
    
    # Palabras especÃ­ficas para anÃ¡lisis econÃ³mico/polÃ­tico
    'equilibrio fiscal', 'instituciones', 'sostenibilidad', 'inflaciÃ³n',
    'inversiÃ³n', 'confianza', 'mercado', 'competitividad', 'productividad',
    'crecimiento econÃ³mico', 'estabilidad', 'reforma', 'polÃ­tica monetaria',
    'polÃ­tica fiscal', 'regulaciÃ³n', 'gobernanza', 'transparencia',
    'deuda pÃºblica', 'reservas internacionales', 'tipo de cambio', 'comercio exterior',
    
    # Palabras de ejemplos histÃ³ricos y comparaciÃ³n internacional
    'comparaciÃ³n internacional', 'ejemplo histÃ³rico', 'precedente', 'similar a',
    'como en', 'en paÃ­ses', 'internacionalmente', 'histÃ³ricamente',
    
    # Palabras que indican anÃ¡lisis de datos y fuentes
    'segÃºn', 'informÃ³', 'reportÃ³', 'indicÃ³', 'revelÃ³', 'demostrÃ³', 'mostrÃ³',
    'evidencia', 'datos', 'cifras', 'estadÃ­sticas', 'estudio', 'investigaciÃ³n',
    'encuesta', 'informe', 'anÃ¡lisis', 'conclusiÃ³n', 'resultado'
}

def _is_topic_trivial_or_contextual(topic_title: str) -> bool:
    """Verifica si un tÃ³pico es trivial o contextual (debe ser rechazado).
    Retorna True si debe ser RECHAZADO (es trivial)."""
    topic_lower = topic_title.lower()
    
    # Verificar patrones excluidos
    for pattern in EXCLUDED_TOPIC_PATTERNS:
        if re.search(pattern, topic_lower, re.IGNORECASE):
            print(f"   âŒ TÃ³pico '{topic_title}' rechazado: PatrÃ³n trivial detectado")
            return True
    
    # Verificar que no sea solo una cobertura de noticia (muy corto + poca sustancia)
    words = topic_title.split()
    if len(words) <= 3:
        # Validar que tenga al menos palabras que sugieran investigaciÃ³n
        has_analysis_keyword = any(keyword in topic_lower for keyword in DEEP_ANALYSIS_KEYWORDS)
        if not has_analysis_keyword:
            print(f"   âš ï¸  TÃ³pico '{topic_title}' muy corto y sin palabras de anÃ¡lisis profundo")
            # No es rechazado pero se marca como advertencia
    
    return False

def _is_topic_similar_to_recent_articles(topic_title: str, recent_articles: List[Dict]) -> bool:
    """Verifica si un tÃ³pico es similar a los artÃ­culos recientes usando palabras clave especÃ­ficas"""
    if not recent_articles or not topic_title:
        return False
    
    generic_words = {
        'argentina', 'argentino', 'argentinos', 'argentinas', 'paÃ­s', 'nacional', 'gobierno', 
        'polÃ­tica', 'polÃ­tico', 'polÃ­ticos', 'polÃ­ticas', 'deportes', 'deporte', 'deportivos',
        'economia', 'econÃ³mico', 'econÃ³micos', 'econÃ³micas', 'tecnologÃ­a', 'tecnolÃ³gico',
        'entretenimiento', 'cultura', 'cultural', 'sociales', 'social', 'nuevo', 'nueva',
        'Ãºltimas', 'Ãºltimo', 'noticias', 'noticia', 'actualidad', 'hoy', 'ayer', 'semana',
        'mes', 'aÃ±o', 'dÃ­a', 'mundo', 'internacional', 'global', 'local', 'nacional',
        'pÃºblico', 'pÃºblica', 'privado', 'privada', 'importante', 'gran', 'grande', 'mayor',
        'mejor', 'primera', 'primer', 'segundo', 'tercero', 'sobre', 'para', 'con', 'sin',
        'desde', 'hasta', 'entre', 'por', 'en', 'de', 'del', 'la', 'el', 'los', 'las',
        'un', 'una', 'unos', 'unas', 'este', 'esta', 'estos', 'estas', 'ese', 'esa'
    }
    
    topic_keywords = set(word.lower() for word in topic_title.lower().split() 
                       if word.lower() not in generic_words and len(word) > 2)
    
    for article in recent_articles:
        article_title = article.get('title', '').lower()
        article_excerpt = article.get('excerpt', '').lower()
        
        article_keywords = set()
        for word in (article_title + ' ' + article_excerpt).split():
            if word.lower() not in generic_words and len(word) > 2:
                article_keywords.add(word.lower())
        
        common_keywords = topic_keywords.intersection(article_keywords)
        
        if len(common_keywords) >= 3:
            similarity_ratio = len(common_keywords) / max(len(topic_keywords), 1)
            if similarity_ratio > 0.6:
                print(f"   âš ï¸ TÃ³pico '{topic_title}' MUY similar a artÃ­culo '{article.get('title')}' (similitud: {similarity_ratio:.2f})")
                print(f"   ğŸ”‘ Palabras especÃ­ficas en comÃºn: {list(common_keywords)}")
                return True
    
    return False

def _normalize_title_capitalization(title: str) -> str:
    """Normaliza capitalizaciÃ³n: solo primera letra mayÃºscula + nombres propios.
    Ejemplo: 'EL DÃ“LAR BLUE ALCANZA NUEVO MÃXIMO' -> 'El dÃ³lar blue alcanza nuevo mÃ¡ximo'"""
    
    if not title or len(title.strip()) == 0:
        return title
    
    # Diccionario de nombres propios comunes en Argentina
    proper_nouns = {
        'argentina', 'buenos aires', 'cÃ³rdoba', 'mendoza', 'rosario',
        'tucumÃ¡n', 'salta', 'misiones', 'gpt', 'gpt-4', 'ia', 'eeuu', 'usa',
        'banco central', 'bcra', 'afip', 'indec', 'senado', 'diputados',
        'congreso', 'gobierno', 'casa rosada', 'merval', 'bitcoin', 'ethereum',
        'apple', 'google', 'meta', 'amazon', 'tesla', 'microsoft', 'openai',
        'messi', 'maradona', 'milei', 'cristina'
    }
    
    # Palabras que deben mantenerse en minÃºsculas
    lowercase_words = {'de', 'la', 'los', 'las', 'el', 'un', 'una', 'y', 'o', 'en', 'a', 'del', 'al', 'por', 'para', 'con', 'sin', 'sobre', 'entre'}
    
    title_normalized = title.strip()
    words = title_normalized.split()
    result = []
    
    for i, word in enumerate(words):
        # Preservar puntuaciÃ³n
        punctuation = ''
        clean_word = word
        while clean_word and clean_word[-1] in '.,!?;:-':
            punctuation = clean_word[-1] + punctuation
            clean_word = clean_word[:-1]
        
        word_lower = clean_word.lower()
        
        # Primera palabra siempre con mayÃºscula
        if i == 0:
            result.append(clean_word[0].upper() + clean_word[1:].lower() + punctuation if clean_word else '')
        # Nombre propio
        elif word_lower in proper_nouns:
            result.append(clean_word[0].upper() + clean_word[1:].lower() + punctuation if clean_word else '')
        # Palabras a mantener en minÃºsculas
        elif word_lower in lowercase_words:
            result.append(clean_word.lower() + punctuation)
        # Resto en minÃºsculas
        else:
            result.append(clean_word.lower() + punctuation)
    
    return ' '.join(result)

def _validate_article_depth(article_content: str) -> Dict[str, Any]:
    """Valida que el artÃ­culo sea anÃ¡lisis profundo, no cobertura superficial.
    VersiÃ³n mejorada con:
    - Peso aumentado en anÃ¡lisis keywords (50 puntos en lugar de 30)
    - DetecciÃ³n de pÃ¡rrafos sustanciales (70+ palabras, no 50+)
    - ValidaciÃ³n de longitud mÃ­nima de pÃ¡rrafos
    - Mejor detecciÃ³n de contexto y evidencia
    
    Retorna {'is_valid': bool, 'issues': [list], 'depth_score': float}"""
    
    content_lower = article_content.lower()
    issues = []
    depth_score = 0.0
    
    # 1. ANÃLISIS KEYWORDS - Peso aumentado de 30 a 50 puntos
    has_analysis_keywords = sum(1 for keyword in DEEP_ANALYSIS_KEYWORDS if keyword in content_lower)
    # MÃ¡s keywords = mayor puntuaciÃ³n, mÃ¡x 50 puntos (3 puntos por keyword)
    analysis_score = min(has_analysis_keywords * 3, 50)
    depth_score += analysis_score
    
    # 2. MÃšLTIPLES SECCIONES - 25 puntos si tiene 3+ secciones
    section_count = len(re.findall(r'^##\s+', article_content, re.MULTILINE))
    has_multiple_sections = section_count >= 3
    depth_score += 25 if has_multiple_sections else 0
    
    # 3. ESTADÃSTICAS Y DATOS - 20 puntos si contiene nÃºmeros/cifras
    has_statistics = bool(re.search(r'\d+(%|\$|M|B|k|mil|millones|%)?(?:\s|:|\.|-|,|$)', article_content))
    depth_score += 20 if has_statistics else 0
    
    # 4. CONTEXTO Y EVIDENCIA - 15 puntos
    has_context = bool(re.search(
        r'(segÃºn|informÃ³|reportÃ³|indicÃ³|revelÃ³|demostrÃ³|mostrÃ³|evidencia|'
        r'datos muestran|estudios demuestran|investigaciÃ³n|estudio|encuesta|'
        r'comparaciÃ³n internacional|ejemplo histÃ³rico|precedente)',
        content_lower
    ))
    depth_score += 15 if has_context else 0
    
    # 5. PÃRRAFOS SUSTANCIALES - Mejorado: mÃ­nimo 70 palabras, no 50
    # Divide el contenido en pÃ¡rrafos "reales" (con mÃ­nimo 70 palabras)
    paragraphs = []
    for para in article_content.split('\n\n'):
        para_clean = para.strip()
        # Excluir lÃ­neas de encabezado, listas cortas, etc.
        if not para_clean.startswith('#') and not para_clean.startswith('-'):
            word_count = len(para_clean.split())
            # Solo contar pÃ¡rrafos de 70+ palabras como "sustanciales"
            if word_count >= 70:
                paragraphs.append(para_clean)
    
    paragraph_count = len(paragraphs)
    # MÃ¡ximo 10 puntos por pÃ¡rrafos sustanciales (mÃ­nimo 4 de 70+ palabras)
    depth_score += min(max(paragraph_count - 3, 0) * 2, 10)
    
    # 6. VALIDACIONES Y PUNTUACIÃ“N FINAL
    
    # ValidaciÃ³n 1: Profundidad total
    if depth_score < 50:
        issues.append(f"Profundidad baja ({depth_score:.0f}/100): falta anÃ¡lisis profundo")
    
    # ValidaciÃ³n 2: AnÃ¡lisis keywords
    if has_analysis_keywords < 8:
        issues.append(f"AnÃ¡lisis insuficiente: solo {has_analysis_keywords} palabras clave de anÃ¡lisis (mÃ­n 8)")
    
    # ValidaciÃ³n 3: PÃ¡rrafos sustanciales
    if paragraph_count < 4:
        issues.append(f"Desarrollo insuficiente: solo {paragraph_count} pÃ¡rrafos sustanciales (mÃ­n 4 de 70+ palabras)")
    
    # ValidaciÃ³n 4: MÃºltiples secciones
    if not has_multiple_sections:
        issues.append(f"Estructura dÃ©bil: solo {section_count} secciones (mÃ­n 3)")
    
    # ValidaciÃ³n 5: Datos/estadÃ­sticas
    if not has_statistics:
        issues.append("Falta respaldo empÃ­rico: sin datos, cifras o estadÃ­sticas")
    
    # ValidaciÃ³n 6: Contexto/Evidencia
    if not has_context:
        issues.append("Sin fuentes o contexto verificable")
    
    is_valid = len(issues) == 0 and depth_score >= 50
    
    return {
        'is_valid': is_valid,
        'issues': issues,
        'depth_score': depth_score,
        'analysis_keywords_count': has_analysis_keywords,
        'section_count': section_count,
        'has_multiple_sections': has_multiple_sections,
        'has_statistics': has_statistics,
        'has_context': has_context,
        'substantive_paragraph_count': paragraph_count,
        'analysis_score': analysis_score
    }

def _convert_html_to_markdown(html_content: str) -> str:
    """Convierte HTML a Markdown para el format_markdown del agente.
    Maneja etiquetas comunes de editors HTML (Quill, DraftJS, etc.)"""
    
    if not html_content:
        return ""
    
    # Unescape HTML entities
    md = html.unescape(html_content)
    
    # Convertir tags HTML a Markdown
    conversions = [
        # PÃ¡rrafos
        (r'<p>(.*?)</p>', r'\1'),
        
        # TÃ­tulos
        (r'<h1>(.*?)</h1>', r'# \1'),
        (r'<h2>(.*?)</h2>', r'## \1'),
        (r'<h3>(.*?)</h3>', r'### \1'),
        (r'<h4>(.*?)</h4>', r'#### \1'),
        
        # Ã‰nfasis
        (r'<strong>(.*?)</strong>', r'**\1**'),
        (r'<b>(.*?)</b>', r'**\1**'),
        (r'<em>(.*?)</em>', r'*\1*'),
        (r'<i>(.*?)</i>', r'*\1*'),
        
        # Listas
        (r'<li>(.*?)</li>', r'- \1'),
        (r'<ul>(.*?)</ul>', r'\1'),
        (r'<ol>(.*?)</ol>', r'\1'),
        
        # Saltos de lÃ­nea
        (r'<br\s*/?>', r'\n'),
        (r'<br/>', r'\n'),
        
        # Enlaces (si existen)
        (r'<a\s+href=["\']([^"\']*)["\']>(.*?)</a>', r'[\2](\1)'),
    ]
    
    for pattern, replacement in conversions:
        md = re.sub(pattern, replacement, md, flags=re.IGNORECASE | re.DOTALL)
    
    # Limpiar tags residuales
    md = re.sub(r'<[^>]+>', '', md)
    
    # Limpiar espacios excesivos
    md = re.sub(r'\n{3,}', '\n\n', md)
    md = md.strip()
    
    return md

def create_prompt(agent, trends_data: Dict[str, Any], search_results: Dict[str, Any], selected_trend: str, topic_position: int = None) -> str:
    """Crea el prompt para ChatGPT basado en las tendencias y bÃºsquedas"""
    trends_data = _validate_and_parse_data(trends_data, "trends_data")
    search_results = _validate_and_parse_data(search_results, "search_results")
    
    trends_text = ""
    trending_topics = trends_data.get("trending_topics", [])
    if isinstance(trending_topics, list) and trending_topics:
        for i, topic in enumerate(trending_topics, 1):
            title = ""
            categories_text = ""
            search_volume = ""
            
            if isinstance(topic, dict):
                title = topic.get('title', '')
                if isinstance(title, dict):
                    title = title.get('query', str(title))
                
                categories = topic.get('categories', [])
                if isinstance(categories, list) and categories:
                    category_names = []
                    for cat in categories:
                        if isinstance(cat, dict):
                            cat_name = cat.get('name', '')
                            if cat_name:
                                category_names.append(cat_name)
                        elif isinstance(cat, str):
                            category_names.append(cat)
                    
                    if category_names:
                        categories_text = f" [CategorÃ­as: {', '.join(category_names)} ]"
                
                volume = topic.get('search_volume')
                if volume:
                    search_volume = f" (Vol: {volume:,})"
                    
            elif isinstance(topic, str):
                title = topic
            
            if title:
                trends_text += f"{i}. {title}{categories_text}{search_volume}\n"
    
    additional_info = ""
    
    if isinstance(search_results, dict) and "top_stories" in search_results:
        top_stories = search_results["top_stories"]
        if isinstance(top_stories, list) and top_stories:
            additional_info += "NOTICIAS DESTACADAS:\n"
            for i, story in enumerate(top_stories[:3], 1):
                if isinstance(story, dict):
                    title = story.get('title', 'Sin tÃ­tulo')
                    source = story.get('source', 'Sin fuente')
                    date = story.get('date', 'Sin fecha')
                    additional_info += f"{i}. {title}\n   Fuente: {source} - {date}\n"
            additional_info += "\n"
    
    if isinstance(search_results, dict) and "organic_results" in search_results:
        organic_results = search_results["organic_results"]
        if isinstance(organic_results, list) and organic_results:
            additional_info += "INFORMACIÃ“N ADICIONAL:\n"
            organic_sorted = []
            for result in organic_results:
                if isinstance(result, dict):
                    organic_sorted.append(result)
            
            organic_sorted = sorted(organic_sorted, key=lambda x: x.get('position', 999))[:3]
            
            for i, result in enumerate(organic_sorted, 1):
                title = result.get('title', 'Sin tÃ­tulo')
                snippet = result.get('snippet', 'Sin descripciÃ³n')
                position = result.get('position', 'N/A')
                if len(snippet) > 100:
                    snippet = snippet[:97] + "..."
                additional_info += f"{i}. [Pos. {position}] {title}\n   {snippet}\n"
    
    personality = agent.personality
    trending_instructions = agent.trending_prompt
    format_template = agent.format_markdown
    
    # Mejorada conversiÃ³n de formato_markdown (HTML â†’ Markdown)
    if format_template and format_template.strip():
        format_template = _convert_html_to_markdown(format_template)
    else:
        # Template por defecto si no estÃ¡ disponible
        format_template = """
# [TÃ­tulo conciso, sobrio]

[IntroducciÃ³n contextual - pÃ¡rrafo que establezca el contexto y la pregunta central]

## ğŸ“Š Panorama actual

[AnÃ¡lisis de la situaciÃ³n presente con datos y contexto - 70-100 palabras]

## ğŸŒ ComparaciÃ³n internacional

[Ejemplos de otros paÃ­ses y cÃ³mo han abordado situaciones similares - 70-100 palabras]

## ğŸ“ˆ Implicancias [especÃ­ficas del tema]

[AnÃ¡lisis de consecuencias sociales, polÃ­ticas o econÃ³micas - 70-100 palabras]

[ConclusiÃ³n con proyecciÃ³n o advertencia - 70-100 palabras]"""

    # ConstrucciÃ³n del prompt mejorado con Ã©nfasis en anÃ¡lisis riguroso
    prompt = f"""{personality}

ğŸ“Š CONTEXTO DE TENDENCIAS (Ãºltimas 24h):
{trends_text}

{additional_info}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

TÃ“PICO ASIGNADO PARA ANÃLISIS: "{selected_trend}"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

CATEGORÃAS DISPONIBLES (debes elegir UNA):
1. "EconomÃ­a y Finanzas" - economÃ­a, dÃ³lar, inflaciÃ³n, bancos, inversiones, mercados, empresas, deuda, polÃ­tica fiscal
2. "TecnologÃ­a e InnovaciÃ³n" - tecnologÃ­a, apps, internet, IA, smartphones, software, startups, transformaciÃ³n digital
3. "PolÃ­tica y Sociedad" - polÃ­tica, gobierno, elecciones, leyes, sociedad, instituciones, gobernanza, regulaciÃ³n
4. "Entretenimiento y Bienestar" - deportes, famosos, mÃºsica, TV, salud, lifestyle, turismo, bienestar

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ¯ MISIÃ“N CRÃTICA - ANÃLISIS PROFUNDO O RECHAZO:

FinGuru publica SOLO anÃ¡lisis profundo de investigaciÃ³n. Tu artÃ­culo SERÃ VALIDADO 
automÃ¡ticamente y RECHAZADO si:
  âŒ Tiene menos de 4 secciones principales
  âŒ Tiene menos de 1500 palabras totales
  âŒ Tiene pÃ¡rrafos menores a 70 palabras
  âŒ Tiene menos de 5 palabras clave de anÃ¡lisis (anÃ¡lisis, impacto, contexto, estrategia, etc)
  âŒ No incluye mÃ­nimo 5 datos, cifras o estadÃ­sticas especÃ­ficas
  âŒ No compara con otros paÃ­ses o precedentes histÃ³ricos
  âŒ Suena a noticia (cobertura superficial) en lugar de anÃ¡lisis

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“‹ ESTRUCTURA OBLIGATORIA (EXACTA):

# TÃ­tulo sobrio (mÃ¡x 12 palabras, primera letra mayÃºscula)

**CATEGORÃA:** [EconomÃ­a y Finanzas / TecnologÃ­a e InnovaciÃ³n / PolÃ­tica y Sociedad / Entretenimiento y Bienestar]

[INTRODUCCIÃ“N: 80-120 palabras. Pregunta central + contexto + por quÃ© importa ahora]

## SituaciÃ³n actual y contexto

[80-120 palabras. Datos especÃ­ficos, cifras verificables, fuentes ("segÃºn", "reportÃ³", "indicÃ³"). NO generalizaciones.]

## AnÃ¡lisis de causas y factores

[80-120 palabras. Por quÃ© ocurre esto. Causas raÃ­z. Conexiones causales. Contexto histÃ³rico.]

## ComparaciÃ³n internacional e impacto global

[80-120 palabras. OBLIGATORIO: precedentes en otros paÃ­ses, cÃ³mo lo manejan, lecciones internacionales. 
Incluir ejemplos especÃ­ficos con datos (ej: "En Chile..." / "HistÃ³ricamente en 2019...")]

## Implicancias y consecuencias

[80-120 palabras. Impacto econÃ³mico/social/polÃ­tico especÃ­fico. CÃ³mo afecta a Argentina, ciudadanos, empresas.]

## Perspectiva estratÃ©gica y outlook futuro

[80-120 palabras. ProyecciÃ³n a futuro. Riesgos y oportunidades. Recomendaciones estratÃ©gicas o reflexiÃ³n final.]

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ”¥ CONTENIDO REQUERIDO (TODO OBLIGATORIO):

PALABRAS CLAVE DE ANÃLISIS (debes incluir 15+):
âœ“ anÃ¡lisis / investigaciÃ³n / estudio
âœ“ impacto / consecuencias / implicaciones
âœ“ estrategia / contexto / antecedentes
âœ“ causas / factores / drivers
âœ“ comparaciÃ³n / internacional / precedente
âœ“ datos / cifras / estadÃ­sticas / demostrÃ³ / revelÃ³ / indicÃ³
âœ“ evidencia / perspectiva / tendencia
âœ“ Usa estas palabras naturalmente en cada secciÃ³n

DATOS Y CIFRAS (MÃNIMO 5):
âœ“ Cifras especÃ­ficas con fuente (ej: "segÃºn INDEC, la inflaciÃ³n fue X%")
âœ“ Comparativas numÃ©ricas (ej: "50% mÃ¡s que en 2023")
âœ“ Datos internacionales (ej: "en Brasil alcanzÃ³ X, mientras que en Argentina Y")
âœ“ HistÃ³ricos (ej: "a diferencia de 2019 cuando fue 20%")
âœ“ NO nÃºmeros genÃ©ricos, TODOS con contexto y fuente

ANÃLISIS PROFUNDO:
âœ“ Causas: Â¿por quÃ© ocurre? Â¿quÃ© factores lo provocan?
âœ“ Contexto: Â¿quÃ© pasÃ³ antes? Â¿precedentes histÃ³ricos?
âœ“ ComparaciÃ³n: Â¿cÃ³mo se maneja en otros paÃ­ses? Â¿precedentes internacionales?
âœ“ Impacto: Â¿quÃ© consecuencias tiene? Â¿para quiÃ©n? Â¿cuantificable?
âœ“ ConclusiÃ³n: Â¿quÃ© significa esto? Â¿quÃ© esperar?

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ ESTÃNDARES DE VALIDACIÃ“N (PARA APROBACIÃ“N):

Profundidad Score (debe ser 60+):
  + 3 puntos por cada palabra clave de anÃ¡lisis (mÃ¡x 50 puntos)
  + 25 puntos si tiene 4+ secciones principales
  + 20 puntos si tiene 5+ datos/cifras especÃ­ficas
  + 15 puntos si incluye contexto internacional o comparativo

PÃ¡rrafos Sustanciales:
  âœ“ Cada pÃ¡rrafo DEBE tener 70-120 palabras (validado automÃ¡ticamente)
  âœ“ MÃ­nimo 4 pÃ¡rrafos de anÃ¡lisis (no contando introducciÃ³n)
  âœ“ NO pÃ¡rrafos cortos, NO listas, NO fragmentos

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âŒ NO HAGAS (CausarÃ¡ rechazo automÃ¡tico):

â€¢ "El dÃ³lar subiÃ³ 2%" â†’ Falta anÃ¡lisis
â€¢ PÃ¡rrafos menores a 70 palabras
â€¢ Una sola secciÃ³n de contenido
â€¢ Cobertura de noticias sin contexto
â€¢ Datos sin fuente o contexto
â€¢ Conclusiones vagas o sin sustancia
â€¢ Menos de 4 secciones principales
â€¢ Olvida comparaciÃ³n internacional
â€¢ TÃ­tulos genÃ©ricos como "AnÃ¡lisis del tema"
â€¢ ArtÃ­culos menores a 1200 palabras

âœ… SÃ HAZ (SerÃ¡ aprobado):

â€¢ "Por quÃ© el dÃ³lar se devalÃºa en contextos de inflaciÃ³n dual: comparaciÃ³n vs Brasil, Chile y precedentes histÃ³ricos"
â€¢ PÃ¡rrafos de 80-120 palabras con datos especÃ­ficos
â€¢ MÃ­nimo 5 secciones temÃ¡ticas bien desarrolladas
â€¢ AnÃ¡lisis de causas, consecuencias, impacto
â€¢ Datos con fuente: "segÃºn BCRA, las reservas cayeron X%"
â€¢ ConclusiÃ³n con outlook estratÃ©gico
â€¢ ComparaciÃ³n explÃ­cita internacional
â€¢ ArtÃ­culos de 1500+ palabras
â€¢ MÃ­nimo 8 palabras clave de anÃ¡lisis distribuidas

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸš€ INSTRUCCIONES FINALES:

1. ESTRUCTURA: Escribe exactamente 6 secciones (intro + 5 ## secciones)
2. PROFUNDIDAD: Cada secciÃ³n 80-120 palabras, 4+ datos/cifras, comparaciÃ³n internacional
3. ANÃLISIS: Incluye causas, contexto, impacto, perspectiva futura
4. PALABRAS CLAVE: Usa naturalmente anÃ¡lisis, impacto, contexto, estrategia, comparaciÃ³n, etc.
5. TOTAL: 1500+ palabras con mÃºltiples datos y cifras
6. FORMATO: Solo Markdown, lÃ­nea 1 = tÃ­tulo, lÃ­nea 2 = categorÃ­a
7. VALIDACIÃ“N: Tu artÃ­culo pasarÃ¡ por anÃ¡lisis de profundidad automÃ¡tico - cumple todo

RECUERDA: Si tu artÃ­culo no cumple estos requisitos, serÃ¡ RECHAZADO automÃ¡ticamente.
Tu misiÃ³n es generar anÃ¡lisis profundo de 1500+ palabras con mÃ­nimo 5 datos/cifras,
comparaciÃ³n internacional, y mÃºltiples secciones temÃ¡ticas. NO cobertura de noticias.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
1. "EconomÃ­a y Finanzas" - economÃ­a, dÃ³lar, inflaciÃ³n, bancos, inversiones, mercados, empresas, deuda, polÃ­tica fiscal
2. "TecnologÃ­a e InnovaciÃ³n" - tecnologÃ­a, apps, internet, IA, smartphones, software, startups, transformaciÃ³n digital
3. "PolÃ­tica y Sociedad" - polÃ­tica, gobierno, elecciones, leyes, sociedad, instituciones, gobernanza, regulaciÃ³n
4. "Entretenimiento y Bienestar" - deportes, famosos, mÃºsica, TV, salud, lifestyle, turismo, bienestar

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ¯ ENFOQUE EDITORIAL - ANÃLISIS RIGUROSO, NO COBERTURA DE NOTICIAS:

FinGuru es un portal de ANÃLISIS PROFUNDO E INVESTIGACIÃ“N, NO de noticias superficiales.
Tu contenido DEBE ser riguroso, equilibrado, fundamentado en datos y perspectiva histÃ³rica.

âŒ NO ESCRIBAS (Superficial):
   â€¢ "El dÃ³lar subiÃ³ 2%" â†’ Coverede vacÃ­a de anÃ¡lisis
   â€¢ "Se jugÃ³ el clÃ¡sico River-Boca" â†’ Noticia sin contexto investigativo
   â€¢ "Messi gana BalÃ³n de Oro" â†’ InformaciÃ³n sin anÃ¡lisis econÃ³mico/social
   â€¢ PÃ¡rrafos menores a 70 palabras â†’ Desarrollo insuficiente
   â€¢ Un pÃ¡rrafo sobre el tema â†’ AnÃ¡lisis incompleto

âœ… ESCRIBE (AnÃ¡lisis riguroso):
   â€¢ "Por quÃ© el equilibrio fiscal es prerequisito para la confianza inversora"
   â€¢ "Impacto econÃ³mico del transporte en la estabilidad macroeconÃ³mica de regiones"
   â€¢ "CÃ³mo los acuerdos internacionales afectan competitividad argentina vs Brasil/Chile"
   â€¢ PÃ¡rrafos de 70-100 palabras con anÃ¡lisis â†’ Desarrollo sustancial
   â€¢ MÃ­nimo 5 pÃ¡rrafos argumentativos â†’ Profundidad garantizada

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“‹ ESTRUCTURA REQUERIDA (Adaptada a tu estilo):

{format_template if format_template and format_template.strip() else '''
# [TÃ­tulo conciso y sobrio - primera letra mayÃºscula + nombres propios]

[IntroducciÃ³n: Plantea la pregunta central y contexto. 70-100 palabras]

## ğŸ“Š Panorama actual

[AnÃ¡lisis de la situaciÃ³n presente con datos concretos. 70-100 palabras. 
Incluir: cifras, hechos verificables, fuentes.]

## ğŸŒ ComparaciÃ³n internacional

[Ejemplos de otros paÃ­ses. CÃ³mo han abordado situaciones similares. 70-100 palabras.
Incluir: precedentes internacionales, lecciones histÃ³ricas.]

## ğŸ“ˆ Implicancias [especÃ­ficas del tema]

[AnÃ¡lisis de consecuencias: sociales, polÃ­ticas, econÃ³micas. 70-100 palabras.
Incluir: impacto calculable, datos de impacto.]

## ğŸ”® Perspectiva y advertencias futuras

[ConclusiÃ³n con proyecciÃ³n. Perspectiva de futuro o advertencias. 70-100 palabras.
Incluir: tendencias predictas, recomendaciones, outlook.]
'''}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ REGLAS ESTRICTAS DE CALIDAD (NO NEGOCIABLES):

CONTENIDO Y ANÃLISIS:
âœ“ MUST: Cada secciÃ³n debe tener 70-100 palabras MÃNIMO (no 50-100)
âœ“ MUST: MÃ­nimo 5 pÃ¡rrafos sustanciales de anÃ¡lisis (no 4)
âœ“ MUST: ComparaciÃ³n internacional O ejemplos histÃ³ricos (obligatorio)
âœ“ MUST: 3+ datos/cifras concretas con contexto de dÃ³nde vienen
âœ“ MUST: Fuentes verificables ("segÃºn", "reportÃ³", "demostrÃ³", "datos indican")
âœ“ MUST: AnÃ¡lisis de causas, contexto, consecuencias e impacto
âœ“ PROHIBIDO: PÃ¡rrafos cortos (<70 palabras) o listas superficiales

ESTRUCTURA MARKDOWN:
âœ“ MUST: TÃ­tulo sobrio (primera letra mayÃºscula + nombres propios)
âœ“ MUST: MÃ­nimo 4 secciones ## (no meros ## sin contenido)
âœ“ MUST: Cada secciÃ³n debe desarrollar un aspecto diferente del anÃ¡lisis
âœ“ MUST: Usar **negrita** para datos, cifras, nombres propios, conceptos clave
âœ“ MUST: CategorÃ­a EXACTAMENTE una de las 4 opciones (no inventar)

TONO Y ESTILO:
âœ“ Formal, profesional, periodÃ­stico pero educativo
âœ“ CrÃ­tico pero equilibrado (sin sesgos ideolÃ³gicos fuertes)
âœ“ TÃ©cnico solo cuando es imprescindible
âœ“ Directo, pausado, reflexivo
âœ“ Frases modelo: "Sin instituciones sÃ³lidas, no hay confianza"
âœ“ Evitar exageraciones, mantener rigor analÃ­tico

FORMATO FINAL:
âœ“ 1200-1400 palabras en total (no 1100-1200, necesitas mÃ¡s desarrollo)
âœ“ Responde ÃšNICAMENTE con el Markdown
âœ“ SIN explicaciones adicionales antes o despuÃ©s
âœ“ SIN "CATEGORÃA: [...]" dentro del artÃ­culo (agrÃ©galo como comentario HTML o en segunda lÃ­nea)
âœ“ LÃ­nea 1: # TÃ­tulo
âœ“ LÃ­nea 2: **CATEGORÃA:** [exacta]
âœ“ LÃ­nea 3+: Desarrollo

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸš€ INSTRUCCIONES FINALES:

1. Lee cuidadosamente el tÃ³pico: "{selected_trend}"
2. Elige la CATEGORÃA que mejor se ajuste
3. Analiza profundamente: Â¿por quÃ© importa? Â¿contexto? Â¿comparaciÃ³n? Â¿impacto?
4. Busca datos, cifras, precedentes internacionales
5. Estructura con mÃ­nimo 5 pÃ¡rrafos sustanciales (70+ palabras cada uno)
6. Escribe solo el Markdown final
7. No incluyas auto-evaluaciones ni explicaciones

RECUERDA: FinGuru requiere ANÃLISIS RIGUROSO, no noticias. Tu trabajo es explicar 
POR QUÃ‰ algo importa, NO simplemente QUÃ‰ pasÃ³.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"""

    return prompt

def generate_article_content(agent, prompt: str) -> str:
    """Genera el contenido del artÃ­culo usando ChatGPT con parÃ¡metros optimizados.
    
    ParÃ¡metros ajustados para mayor rigor y consistencia:
    - temperature: 0.6 (mÃ¡s enfocado, menos aleatorio que 0.7)
    - top_p: 0.9 (variedad controlada)
    - frequency_penalty: 0.3 (evita repeticiones)
    - presence_penalty: 0.1 (fomenta nuevo contenido)
    """
    try:
        system_message = agent.personality or "Eres un periodista especializado en tendencias argentinas. Responde ÃšNICAMENTE con contenido en formato Markdown."
        
        response = agent.openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_message},
                {"role": "user", "content": prompt}
            ],
            max_tokens=1400,  # Aumentado de 1200 para permitir mÃ¡s desarrollo
            temperature=0.6,   # Reducido de 0.7 para mayor rigor
            top_p=0.9,         # Controlado para variedad
            frequency_penalty=0.3,  # Evita repeticiones
            presence_penalty=0.1    # Fomenta contenido nuevo
        )
        
        return response.choices[0].message.content
    except Exception as e:
        print(f"Error generating content: {str(e)}")
        return ""

def markdown_to_html(md: str) -> str:
    """Convierte Markdown simple a HTML"""
    html = md
    html = html.replace('### ', '<h3>').replace('\n### ', '</h3>\n<h3>')
    html = html.replace('## ', '<h2>').replace('\n## ', '</h2>\n<h2>')
    html = html.replace('# ', '<h1>').replace('\n# ', '</h1>\n<h1>')
    
    html = re.sub(r'\*\*(.*?)\*\*', r'<strong>\1</strong>', html)
    html = re.sub(r'^- (.*)$', r'<li>\1</li>', html, flags=re.MULTILINE)
    html = re.sub(r'\n{2,}', '</p>\n<p>', html)
    html = html.replace('\n', '<br>')
    
    if not html.startswith('<'):
        html = '<p>' + html
    if not html.endswith('>'):
        html = html + '</p>'
    
    html = re.sub(r'<h([123])>([^<]*?)(?=<|$)', r'<h\1>\2</h\1>', html)
    
    return html

def process_article_data(agent_response: str) -> Dict[str, Any]:
    """Procesa la respuesta del agente para la API de fin.guru.
    Incluye normalizaciÃ³n de capitalizaciÃ³n de tÃ­tulos."""
    lines = agent_response.split('\n')
    
    title_line = next((line for line in lines if line.startswith('# ')), None)
    title = title_line.replace('# ', '').strip() if title_line else 'ArtÃ­culo de Tendencia'
    
    # Normalizar capitalizaciÃ³n del tÃ­tulo (solo 1Âª letra mayÃºscula + nombres propios)
    title = _normalize_title_capitalization(title)
    
    category_line = next((line for line in lines if '**CATEGORÃA:**' in line or 'CATEGORÃA:' in line), None)
    category = "Entretenimiento y Bienestar"
    
    if category_line:
        category_match = re.search(r'(?:\*\*)?CATEGORÃA:(?:\*\*)?\s*(.+)', category_line)
        if category_match:
            category = category_match.group(1).strip()
    
    clean_markdown = agent_response
    clean_markdown = re.sub(r'(?:\*\*)?CATEGORÃA:(?:\*\*)?.*\n', '', clean_markdown)
    clean_markdown = re.sub(r'^# .*?\n', '', clean_markdown, count=1)
    clean_markdown = clean_markdown.strip()
    
    paragraphs = [line.strip() for line in clean_markdown.split('\n') 
                 if line.strip() and not line.startswith('#') and not line.startswith('-')]
    excerpt = paragraphs[0][:150] + '...' if paragraphs else 'ArtÃ­culo sobre tendencias'
    
    html_content = markdown_to_html(clean_markdown)
    
    filename = ''.join(random.choices(string.ascii_lowercase + string.digits, k=10)) + '.jpg'
    
    return {
        "title": title,
        "excerpt": excerpt,
        "content": html_content,
        "category": category,
        "publishAs": "",
        "tags": "argentina, tendencias, noticias",
        "detectedCategory": category,
        "fileName": filename
    }

def _validate_and_parse_data(data: Any, data_type: str = "unknown") -> Dict[str, Any]:
    """Valida y convierte datos a diccionario de forma robusta"""
    if data is None:
        print(f"   {data_type} es None")
        return {}
    
    if isinstance(data, dict):
        return data
    
    if isinstance(data, str):
        try:
            parsed = json.loads(data)
            if isinstance(parsed, dict):
                return parsed
            else:
                print(f"   {data_type} JSON no es un objeto: {type(parsed)}")
                return {}
        except json.JSONDecodeError as e:
            print(f"   Error parseando {data_type} JSON: {str(e)}")
            return {}
    
    print(f"   {data_type} tiene tipo inesperado: {type(data)}")
    return {}

def _extract_trend_title(trends_data: Dict[str, Any], position: int = 1) -> str:
    """Extrae el tÃ­tulo del trend en la posiciÃ³n especificada de forma robusta"""
    if not isinstance(trends_data, dict):
        print("   trends_data no es un diccionario vÃ¡lido")
        return ""
    
    trending_topics = trends_data.get("trending_topics", [])
    if not isinstance(trending_topics, list) or not trending_topics:
        print("   No hay trending_topics vÃ¡lidos")
        return ""
    
    if position < 1 or position > len(trending_topics):
        print(f"   PosiciÃ³n {position} fuera de rango. Disponibles: 1-{len(trending_topics)}. Usando posiciÃ³n 1.")
        position = 1
    
    topic_index = position - 1
    selected_topic = trending_topics[topic_index]
    
    print(f"   Seleccionando tÃ³pico en posiciÃ³n #{position} (Ã­ndice {topic_index})")
    
    if isinstance(selected_topic, dict):
        title = selected_topic.get('title', '')
        if isinstance(title, str) and title:
            return title
        
        if isinstance(title, dict):
            query = title.get('query', '')
            if isinstance(query, str) and query:
                return query
        
        for key in ['query', 'name', 'text']:
            value = selected_topic.get(key, '')
            if isinstance(value, str) and value:
                return value
                
    elif isinstance(selected_topic, str):
        return selected_topic
    
    print(f"   No se pudo extraer tÃ­tulo del tÃ³pico en posiciÃ³n {position}: {selected_topic}")
    return ""
