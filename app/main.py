import os
from fastapi import FastAPI, UploadFile, Response, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from openai import OpenAI
from pydantic import BaseModel
from agents.agents import iterate_agents
from utils.clean import clean_message
from utils.auth import validate_token
from load_env import load_env_files
from utils.middleware import check_subscription, check_sudo_api_key
from typing import Optional
from utils.trends_functions import TrendsAPI
from agents.automated_trends_agent import run_multi_trends_agents, clear_trends_cache_standalone, get_cache_status_standalone, get_trending_topics_cached

load_env_files()

openai = OpenAI(
  api_key=os.environ['OPENAI_API_KEY'],
)
app = FastAPI(
    title= "Fingur√∫ API",
    version= "0.1"
)

origins = ["*"]  
methods = ["*"]  
headers = ["*"]  

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_methods=methods,
    allow_headers=headers,
    allow_credentials=True,  
    expose_headers=["*"]     
)

from onlygpt import iterate_many_times

@app.get("/")
async def test():
    return "Test working"

@app.get("/health")
async def health_check():
    """
    Health check endpoint para Cloud Run
    """
    return {
        "status": "healthy",
        "message": "FinGuru API is running",
        "version": "0.1"
    }

@app.post("/convert_audio")
async def convert_audio(file: UploadFile):
    """
    Convert WAV file audio to text using Whisper
    """
    #print(file.content_type)
    save_path = os.path.join("app", file.filename)
    try:
        #listFormats = ["audio/wav","audio/mpeg","video/mp4", "audio/x-m4a"]
        #if (file.content_type not in listFormats):
        #   return Response("Error, el audio no tiene un formato valido", 400)
        
        # Guardar el archivo de audio con su nombre original
        with open(save_path, "wb") as uploaded_file:
            uploaded_file.write(file.file.read())

        # Abrir el archivo de audio guardado
        with open(save_path, "rb") as audio_file:
            transcript = openai.audio.transcriptions.create(
                model="gpt-4o-mini-transcribe",
                file=audio_file,
                response_format='text'
            )

    except Exception as e:
        if os.path.exists(save_path):
            os.remove(save_path)
        return Response(str(e), 400)

    finally:
        # Eliminar el archivo de audio
        if os.path.exists(save_path):
            os.remove(save_path)
    try:        
        new_message = iterate_many_times(transcript, 1)
    except Exception as e:
        return e
    return new_message

from algorand_functions import transfer_tokens

@app.post("/transfer_tokens")
async def _transfer_tokens(address_to_send:str, tokenAmount:float):
    return transfer_tokens(address_to_send, tokenAmount)
    
from db import connect_to_mongo
db = connect_to_mongo()
db = db.db

class ParamsToClaimTokens(BaseModel):
    id: int
    viewsAmount: int
    address: str
    
@app.post("/views")
async def views(data:ParamsToClaimTokens):
    id = data.id
    viewsAmount = data.viewsAmount
    address = data.address
    if viewsAmount < 0:
        return Response("Error, views must be greater than 0", 400)
    
    post = db["finguru"].find({"id":id})
    try:
        post = post[0]

        views_to_claim = viewsAmount - post["views"]
        if views_to_claim > 0:
            post["views"] = viewsAmount
            db["finguru"].update_one({"id":id}, {"$set": post})
        else:
            return Response("Error", 400)
    except:
        db["finguru"].insert_one({"id":id, "views":viewsAmount})
        views_to_claim = viewsAmount

    if views_to_claim <= 0:
        return Response("Error, no hay tokens para enviar", status_code=400)
    return transfer_tokens(address, views_to_claim*10**18)
    #return f"{views_to_claim} Tokens transfers to {address}"

class TextInput(BaseModel):
    text: str

class MultiAgentRequest(BaseModel):
    topic_position: Optional[int] = None
    token: Optional[str] = None

@app.post("/convert_text_v2")
async def convert_text(data: TextInput, user: dict = Depends(check_subscription)):
    """
    Convierte texto de entrada en un nuevo mensaje procesado por m√∫ltiples agentes.

    Esta funci√≥n toma un texto de entrada, lo procesa a trav√©s de una serie de agentes
    y devuelve un mensaje limpio y formateado.

    Args:
        data (TextInput): Un objeto que contiene el texto a procesar.
        user (dict): Informaci√≥n del usuario autenticado (inyectada por validate_token).

    Returns:
        str: El mensaje procesado y limpio.

    Raises:
        HTTPException: Si ocurre un error durante el procesamiento.
    """
    try:
        new_message = iterate_agents(f"Hecho, nota o tema: {data.text}")
    except Exception as e:
        return HTTPException(status_code=400, detail=str(e))
    return clean_message(new_message)

@app.post("/convert_audio_v2")
async def convert_audio(file: UploadFile, user: dict = Depends(check_subscription)):
    """
    Convierte un archivo de audio en texto y luego lo procesa con m√∫ltiples agentes.

    Esta funci√≥n toma un archivo de audio, lo transcribe usando el modelo Whisper de OpenAI,
    y luego procesa la transcripci√≥n a trav√©s de una serie de agentes para generar un nuevo mensaje.

    Args:
        file (UploadFile): El archivo de audio a procesar.
        user (dict): Informaci√≥n del usuario autenticado (inyectada por validate_token).

    Returns:
        str: El mensaje procesado y limpio basado en la transcripci√≥n del audio.

    Raises:
        HTTPException: Si ocurre un error durante el procesamiento del audio o la transcripci√≥n.
    """
    save_path = os.path.join("app", file.filename)
    try:
        # Guardar el archivo de audio con su nombre original
        with open(save_path, "wb") as uploaded_file:
            uploaded_file.write(file.file.read())

        # Abrir el archivo de audio guardado
        with open(save_path, "rb") as audio_file:
            transcript = openai.audio.transcriptions.create(
                model="gpt-4o-mini-transcribe",
                file=audio_file,
                response_format='text'
            )

    except Exception as e:
        if os.path.exists(save_path):
            os.remove(save_path)
        return Response(str(e), 400)

    finally:
        # Eliminar el archivo de audio
        if os.path.exists(save_path):
            os.remove(save_path)

    try:
        transcript_text = transcript
        print(transcript_text)
        new_message = iterate_agents(f"Hecho, nota o tema: {transcript_text}")
        return clean_message(new_message)
    except Exception as e:
        return Response(str(e), 400)

trends_api = TrendsAPI()

@app.get("/trends")
async def get_trending_topics(
    geo: Optional[str] = "AR", 
    hours: Optional[int] = 24,
    language: Optional[str] = "es-419",
    no_cache: Optional[bool] = False,
    count: Optional[int] = 10,
    user: dict = Depends(check_subscription)
):
    """
    ‚ö†Ô∏è ENDPOINT LEGACY: Obtiene tendencias directamente de SerpAPI (consume cuota).
    
    RECOMENDACI√ìN: Usa /trends/cached en su lugar para ahorrar llamadas API.
    
    Args:
        geo: C√≥digo de pa√≠s de dos letras (ej. AR, US, ES)
        hours: N√∫mero de horas para las tendencias (24 por defecto)
        language: C√≥digo de idioma (es-419 para espa√±ol de Latinoam√©rica)
        no_cache: Si se debe deshabilitar el cach√©
        count: N√∫mero de resultados a devolver
        user: Informaci√≥n del usuario autenticado (inyectada por validate_token)
        
    Returns:
        dict: Objeto JSON con las tendencias encontradas
    """
    return trends_api.get_trending_searches_by_category(
        geo=geo, 
        hours=hours,
        language=language,
        no_cache=no_cache,
        count=count
    )

@app.get("/run_multi_trends_agents")
async def execute_multi_trends_agents(
    topic_position: Optional[int] = None,
    sudo_check: dict = Depends(check_sudo_api_key)
):
    """
    üöÄ ENDPOINT OPTIMIZADO: Ejecuta m√∫ltiples agentes con cach√© inteligente de tendencias.

    Esta funci√≥n optimizada:
    1. Obtiene los agentes disponibles desde NEXT_PUBLIC_API_URL/agent-ias
    2. Obtiene las tendencias UNA SOLA VEZ y las comparte entre todos los agentes
    3. Inicializa cada agente con su configuraci√≥n √∫nica (personality, trending, format_markdown)
    4. Ejecuta todos los agentes con las mismas tendencias cached
    5. Publica los art√≠culos autom√°ticamente en fin.guru
    
    ‚ö° AHORRO DE API: En lugar de 5+ llamadas a SerpAPI, solo hace 1 llamada cada 30 minutos.
    
    Headers requeridos:
        X-SUDO-API-KEY: Clave SUDO para acceso administrativo
    
    Args:
        topic_position: Posici√≥n espec√≠fica de tendencia (1-10) o None para auto-selecci√≥n por ChatGPT
        sudo_check: Verificaci√≥n de SUDO_API_KEY (inyectada autom√°ticamente)
        
    Returns:
        dict: Resultado del proceso multi-agente con resumen de √©xitos y fallos
    """
    try:
        result = run_multi_trends_agents(topic_position=topic_position)
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error ejecutando multi-agentes: {str(e)}")

@app.get("/cache/status")
async def get_cache_status_endpoint(user: dict = Depends(check_subscription)):
    """
    Obtiene el estado actual del cach√© de tendencias.
    
    Muestra informaci√≥n √∫til para optimizar el uso de SerpAPI:
    - Si hay datos en cach√©
    - Cu√°ndo expira el cach√© actual
    - N√∫mero de tendencias almacenadas
    
    Returns:
        dict: Estado completo del cach√© incluyendo datos y timestamps
    """
    return get_cache_status_standalone()

@app.post("/cache/clear")
async def clear_cache_endpoint(user: dict = Depends(check_subscription)):
    """
    Limpia manualmente el cach√© de tendencias.
    
    √ötil cuando:
    - Quieres forzar una nueva consulta a SerpAPI
    - Has cambiado configuraciones y necesitas datos frescos
    - Hay problemas con datos cached
    
    Returns:
        dict: Confirmaci√≥n de que el cach√© fue limpiado
    """
    return clear_trends_cache_standalone()

@app.get("/trends/cached")
async def get_cached_trends(
    geo: Optional[str] = "AR", 
    hours: Optional[int] = 24,
    language: Optional[str] = "es-419",
    count: Optional[int] = 10,
    user: dict = Depends(check_subscription)
):
    """
    üöÄ ENDPOINT OPTIMIZADO: Obtiene tendencias usando cach√© inteligente.
    
    Este endpoint utiliza un sistema de cach√© de 30 minutos para minimizar las llamadas a SerpAPI.
    Perfecto para conservar tus 100 llamadas mensuales.
    
    Args:
        geo: C√≥digo de pa√≠s de dos letras (ej. AR, US, ES)
        hours: N√∫mero de horas para las tendencias (24 por defecto)
        language: C√≥digo de idioma (es-419 para espa√±ol de Latinoam√©rica)
        count: N√∫mero de resultados a devolver
        user: Informaci√≥n del usuario autenticado
        
    Returns:
        dict: Tendencias con informaci√≥n de cach√© (cached: true/false)
    """
    return get_trending_topics_cached()